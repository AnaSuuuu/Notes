# 信源和信源熵

## 离散平稳信源

若信源 $X$ 输出随机序列的**各维联合概率分布均与时间起点无关**，则信源是完全平稳的。

对于离散平稳信源来说，其各维条件概率与时间起点无关，只与关联长度有关。


## 马尔可夫信源

对于二元二阶马尔可夫信源，其信源符号集共有 $2$ 种符号、状态集共有 $4$ 种状态，信源输出的符号只与其前面 $2$ 个符号有关，依赖长度为 $3$。

$H_{\infty} = H_{m + 1} = \sum_{i = 1}^J p(E_i)H(X|E_i)$。

其中 $H(X|E_i) = -\sum_{j = 1}^q p(a_k|E_i)\log p(a_k | E_i)$。

对于遍历的有限状态马尔科夫链，如果初始概率分布不是平稳分布，当转移步数足够大时，状态概率分布一定趋于平稳分布。


## 信源的相关性和剩余度

熵的相对率：$\eta = \dfrac{H_{\infty}}{H_0}$。

信源剩余度：$r = 1 - \eta = 1 - \dfrac{H_{\infty}}{H_0}$。

其中 $H_0$ 是最大熵，一般为 $\log q$。$H_{\infty}$ 是实际熵。

连续熵 $H_c(X) = \int_R p(x)\log p(x)dx$。

**均匀分布**

均匀分布的连续信源的熵

在 $[a, b]$ 区间均匀分布的信息熵为 $\log(b - a)$。

**高斯分布**

高斯分布的连续信源的熵

$$
    p(x) = \dfrac{1}{\sqrt{2\pi\sigma^2}}\exp{\dfrac{(x - m)^2}{2\sigma^2}}
$$

则信源熵为

$$
    H_c(x) = \log \sqrt{2\pi e \sigma^2} = \log \sqrt{2\pi e P}
$$

这里的 $P$ 是平均功率。

**指数分布**

指数分布的连续信源的熵

$$
    p(x) = \lambda\exp{(-\lambda x)}
$$

则信源熵为

$$
    H_c(x) = \log \left (\dfrac{e}{\lambda}\right)
$$

**拉普拉斯分布**

拉普拉斯分布的连续信源的熵

$$
    p(x) = \dfrac{1}{2}\lambda\exp{(-\lambda |x|)}
$$

则信源熵为

$$
    H_c(x) = \log \left (\dfrac{e}{\lambda}\right) + 1
$$

若信源输出的幅度被限定在 $[a, b]$ 区域内，则当输出信号的概率密度是均匀分布时，信源具有最大熵。其值等于 $\log (b - a)$。

若连续信源输出信号的平均功率被限定为 $S$，则其输出信号幅度服从高斯分布时信源具有最大熵。其值等于 $\log \sqrt{2\pi e S}$。

若连续信源输出非负信号的均值被限定为 $m$，则其输出信号幅度服从指数分布时，信源具有最大熵。其值等于 $\log (me)$。





